{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapovanie nazvov clankov pre 3 jazykove verzie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projekt Vyhladavanie informacii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nikoleta Hroncová"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tento cyklus predstavuje predspracovanie dát. Výsledkom je finálny súbor, ktorého obsahom sú na každom riadku jazykové verzie názvu článku z Wikipédie, oddelené bodkočiarkami. Finálny súbor má približne 250 MB - 6.9 milióna riadkov. Tento kód sa nebude vykonávať stále, stačilo ho spustiť raz, potom sa už pracuje len s vytvoreným súborom tak, že ho načítame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "shortenedFile = open(\"shortenedFileDic.txt\", \"a\")\n",
    "spanishPattern = '.es\\..'\n",
    "frenchPattern = '.fr\\..'\n",
    "englishPattern = './/dbped.'\n",
    "qEntityPattern = '/entity/Q.'\n",
    "englishPrefix = 'en:'\n",
    "frenchPrefix = 'fr:'\n",
    "spanishPrefix = 'es:'\n",
    "\n",
    "interlanguageLinks = open(\"/home/nikoleta/Documents/School/ING/VINF/interlanguage_links_en.ttl\", \"r\")\n",
    "check = 0\n",
    "for line in interlanguageLinks:\n",
    "    splittedLine = line.split(' ')\n",
    "    splittedLine =  splittedLine[2]\n",
    "    spanish = re.search(spanishPattern, splittedLine)\n",
    "    french = re.search(frenchPattern, splittedLine)\n",
    "    english = re.search(englishPattern, splittedLine)\n",
    "    if(re.search(qEntityPattern, splittedLine) and check is 0):\n",
    "        check += 1 \n",
    "    elif(re.search(qEntityPattern, splittedLine) and check is not 0):\n",
    "        shortenedFile.write('\\n')\n",
    "    if spanish or french or english:\n",
    "        if spanish:\n",
    "            prefix = spanishPrefix\n",
    "        elif english:\n",
    "            prefix = englishPrefix\n",
    "        elif french:\n",
    "            prefix = frenchPrefix\n",
    "        splittedLine = splittedLine.split(\"/\")\n",
    "        articleName = splittedLine[4]\n",
    "        temp = articleName.split(\">\")\n",
    "        name = temp[0]\n",
    "        name = name.replace(\"_\", \" \")\n",
    "        shortenedFile.write(prefix + \" \" + name + \"; \")    \n",
    "    \n",
    "interlanguageLinks.close()\n",
    "shortenedFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naivný spôsob hľadania stringu v súbore. Pracuje pomaly, najmä pre stringy respektíve názvy, ktoré sa nachádzajú na konci súboru. Prechádza celý súbor po riadkoch a hľadá zhodu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: 2016 Erste Bank Open; fr: Tournoi de tennis de Vienne (ATP 2016); \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newFile = open(\"shortenedFileDic.txt\", \"r\")\n",
    "for line in newFile:\n",
    "    if \"Tournoi de tennis de Vienne (ATP 2016)\" in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh import index\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import *\n",
    "import os.path\n",
    "from whoosh.index import open_dir\n",
    "\n",
    "path = u\"shortenedFileDic.txt\"\n",
    "file = open(path, \"r\")\n",
    "schema = Schema(english=TEXT(stored=True), spanish=TEXT(stored=True), french=TEXT(stored=True))\n",
    "\n",
    "if not os.path.exists(\"index\"):\n",
    "    os.mkdir(\"index\")\n",
    "\n",
    "ix = create_in(\"index\", schema)\n",
    "ix = open_dir(\"index\")\n",
    "writer = ix.writer()\n",
    "\n",
    "for line in file:\n",
    "    line = line.split(';')\n",
    "    indexEs = [i for i, s in enumerate(line) if spanishPrefix in s]\n",
    "    indexEn = [i for i, s in enumerate(line) if englishPrefix in s]\n",
    "    indexFr = [i for i, s in enumerate(line) if frenchPrefix in s]\n",
    "    if indexEn:\n",
    "        english = line[indexEn[0]].split(':')\n",
    "        english = english[1]\n",
    "    if indexEs:\n",
    "        spanish = line[indexEs[0]].split(':')\n",
    "        spanish = spanish[1]\n",
    "    else:\n",
    "        spanish = ''\n",
    "    if indexFr:\n",
    "        french = line[indexFr[0]].split(':')\n",
    "        french = french[1]\n",
    "    else:\n",
    "        french = ''\n",
    "    writer.add_document(english=english, spanish=spanish, french=french)\n",
    "\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Hit {'english': ' Jack Bauer', 'french': ' Jack Bauer', 'spanish': ' Jack Bauer'}>\n"
     ]
    }
   ],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    "with ix.searcher() as searcher:\n",
    "    query = QueryParser(\"english\", ix.schema).parse(u\"Jack Bauer OR (spanish:Jack Bauer) OR (french:Jack Bauer)\")\n",
    "    results = searcher.search(query)\n",
    "    print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Jack Bauer\n",
      " Jack Bauer\n",
      " Jack Bauer\n",
      " Africa\n",
      " África\n",
      " Afrique\n",
      " Triskaidekaphobia\n",
      " Triscaidecafobia\n",
      " Triskaïdékaphobie\n",
      " Scotland\n",
      " Escocia\n",
      " Écosse\n",
      " Spain\n",
      " España\n",
      " Espagne\n"
     ]
    }
   ],
   "source": [
    "path = u\"shortenedFileDic.txt\"\n",
    "\n",
    "file = open(path, \"r\")\n",
    "\n",
    "cnt = 0\n",
    "for line in file:\n",
    "    cnt +=1\n",
    "    line = line.split(';')\n",
    "    indexEs = [i for i, s in enumerate(line) if spanishPrefix in s]\n",
    "    indexEn = [i for i, s in enumerate(line) if englishPrefix in s]\n",
    "    indexFr = [i for i, s in enumerate(line) if frenchPrefix in s]\n",
    "    if indexEn:\n",
    "        english = line[indexEn[0]].split(':')\n",
    "        english = english[1]\n",
    "    if indexEs:\n",
    "        spanish = line[indexEs[0]].split(':')\n",
    "        spanish = spanish[1]\n",
    "    if indexFr:\n",
    "        french = line[indexFr[0]].split(':')\n",
    "        french = french[1]\n",
    "    \n",
    "    print(english)\n",
    "    print(spanish)\n",
    "    print(french)\n",
    "    if(cnt is 5):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testovanie indexovania pre malý súbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh import index\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import *\n",
    "import os.path\n",
    "from whoosh.index import open_dir\n",
    "\n",
    "path = u\"missingLanguages.txt\"\n",
    "file = open(path, \"r\")\n",
    "schema = Schema(english=TEXT(stored=True), spanish=TEXT(stored=True), french=TEXT(stored=True))\n",
    "\n",
    "if not os.path.exists(\"index\"):\n",
    "    os.mkdir(\"index\")\n",
    "\n",
    "ix = create_in(\"index\", schema)\n",
    "ix = open_dir(\"index\")\n",
    "writer = ix.writer()\n",
    "\n",
    "for line in file:\n",
    "    line = line.split(';')\n",
    "    indexEs = [i for i, s in enumerate(line) if spanishPrefix in s]\n",
    "    indexEn = [i for i, s in enumerate(line) if englishPrefix in s]\n",
    "    indexFr = [i for i, s in enumerate(line) if frenchPrefix in s]\n",
    "    if indexEn:\n",
    "        english = line[indexEn[0]].split(':')\n",
    "        english = english[1]\n",
    "    if indexEs:\n",
    "        spanish = line[indexEs[0]].split(':')\n",
    "        spanish = spanish[1]\n",
    "    else:\n",
    "        spanish = ''\n",
    "    if indexFr:\n",
    "        french = line[indexFr[0]].split(':')\n",
    "        french = french[1]\n",
    "    else:\n",
    "        french = ''\n",
    "    writer.add_document(english=english, spanish=spanish, french=french)\n",
    "\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Hit {'english': ' Cheirostylis', 'french': '', 'spanish': ' Cheirostylis'}>\n"
     ]
    }
   ],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    "with ix.searcher() as searcher:\n",
    "    query = QueryParser(\"english\", ix.schema).parse(u\"Cheirostylis OR (spanish:Cheirostylis) OR (french:Cheirostylis)\")\n",
    "    results = searcher.search(query)\n",
    "    print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
